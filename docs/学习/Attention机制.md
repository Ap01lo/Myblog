### Attention**机制**

Attention的宏观概念是建立在人的注意力机制上面的。当我们的目光移动到别处时，我们的注意力也会相应的转移，而且注意力的集中点一定在视线内的某一个具体的位置，也就是说，当我们注意到某个场景时，在该场景的内部的每一处的空间位置上注意力的分布是不一样的。但是对于不同的任务，我们的注意力的体现机制又有所区别。对于图片来说，我们会被图片的某一重点部分所吸引，然后逐渐转移注意力，看完整个图片。对于文字来说，我们会带着一定的目的来处理所得到的文字，比如从左到右读完，比如搜索关键的字词，比如翻译成其他的语言。所以，在人脑中处理注意力的方式对不同的任务是有相应的区别的。

**因此，将注意力机制放到计算机这边来，不同任务的注意力机制的实现方式也应该是有所区别的。**

在计算机视觉领域，注意力机制被引入来进行视觉信息处理。它是一种机制，或者方法论，没有严格的数学定义。因此，像传统的局部图像特征提取，显著性检测，滑动窗口方法等都可以看作是一种注意力机制。

在NLP领域，注意力机制现在大多数都是搭配Encoder-Decoder框架得以实现的。传统的Encoder-Decoder的模型也以RNN为主，对于长时间的处理问题也用LSTM,GRU等变体有效解决。简单可解释如下：

对于一个输入 $X$，要得到一个对应的输出 $Y$，这就形成了一个句子对，X-Y的对应可以是：问题-答案，汉语-对应的英语翻译，等等一切实际需要的模型。可以是同一种语言，也可以是不同种的语言，可以长度相同，也可以长度不同，而且分别由各自的语素构成。然后编码解码的原理是，由Encoder将X编码成一个 `语义编码C` ，然后 `语义编码C` 作为Decoder的输入，经过Decoder得到输出Y的一个过程。

如果用公式的话，就可以这么解释：（ $E$ 代表编码系统函数，$D$ 代表解码系统函数）

$X=(x_1,x_2,...,x_m)$

$Y=(y_1,y_2,...,y_n)$

$C=E(x_1,x_2...x_m)$

$y_i=D(C,y_1,y_2...,y_{i-1})$

可以看到，对于输出向量Y来说，Y的每一个元素都是由 生成的语义编码C 以及之前生成的历史状态共同作用的结果。这样就产生了一个问题，如果对于每一个输出元素来说，语义编码C都是一样的，那就意味着输入X的每个元素对每一个输出元素的影响是相同的，甚至可以说，在一定意义上，$i$ 时刻的输出 $y_i$ 只受到之前的历史状态的影响。所以这个模型是没有注意力的。

那么注意力机制是怎么运作的呢？就是在计算输出元素 $y_i$ 之前，找一个对应的 $C_i$ ，再来计算相应的输出。用公式表达如下：

在没有注意力之前

$y_1=D(C)$

$y_2=D(C,y_1)$

$y_3=D(C,y_1,y_2)$

...

$y_n=D(C,y_1,y_2...y_{n-1})$

有了注意力之后

$y_1=D(C_1)$

$y_2=D(C_2,y_1)$

$y_3=D(C_3,y_1,y_2)$

...

$y_n=D(C_n,y_1,y_2...y_{n-1})$

就是产生不同的 $C_i$ 然后作用于不同的输出元素，对于产出的不同的 $C_i$ ，是通过对输入X的每个元素加上不同权值得到的，这样子就可以做到输入的X的每个元素对输出的Y的每个元素的影响是不同的，也就是达到了注意力的目的。

接下来使用一个具体的例子来理一理整个过程。

翻译 `我爱你` 到英文，整个过程的公式表达为：

$X=(我，爱，你)$

$C_1=E(我 \times 0.8 +爱 \times 0.1 +你\times 0.1)$

$y_1=D(	C_1)=I$

$C_2=E(我 \times 0.1 +爱 \times 0.8 +你\times 0.1)$

$y_2=D(C_2,y_1)=love$

$C_3=E(我 \times 0.1 +爱 \times 0.1 +你\times 0.8)$

$y_3=D(C_3,y_1,y_2)=you$

$Y=(I，love，you)$

上面的 0.8，0.1，0.1 的权重是我的假想值，那么对于RNN，它是由此时刻的输出 $H_i$ 与每个输入所对应的隐藏层状态一起作用于一个处理函数，然后这个处理函数通过 SoftMax 函数就生成了对应的权重值。

$W_A=SoftMax(f(H_i,h_1,h_2,...,h_{i-1}))$

这就是我所理解的注意力机制，感觉在理了一遍思路之后，通透了很多，对一些细节理解的更深刻了。这是在参考了一些博客和相关论文之后得到的解释，不知道实际上到底对还是不对。



